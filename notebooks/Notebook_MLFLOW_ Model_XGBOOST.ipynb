{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b01d4-39ce-405e-9160-32beb4472d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "#from sklearn.compose import ColumnTransformer\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#import xgboost as xgb\n",
    "#from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "#import scipy.stats as stats\n",
    "#from statsmodels.graphics.tsaplots import plot_acf\n",
    "#from scipy.stats import skew, kurtosis, probplot\n",
    "#from statsmodels.stats.stattools import jarque_bera\n",
    "#from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "#from scipy.stats import shapiro\n",
    "#from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "#from lightgbm import LGBMRegressor\n",
    "#import lightgbm as lgb\n",
    "#from lightgbm import early_stopping\n",
    "#from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, mean_absolute_error, r2_score, make_scorer\n",
    "#from sklearn.model_selection import cross_validate\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#import plotly.graph_objects as go\n",
    "#import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34e335c-12b0-4564-9bb7-bc4799510411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import warnings\n",
    "#warnings.simplefilter(action='ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91dec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlflow\n",
    "#!pip install --upgrade jinja2\n",
    "#!pip install --upgrade Flask\n",
    "#!pip install setuptools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d65537",
   "metadata": {},
   "source": [
    "### Plan d‚ÄôAction\n",
    "D√©marrer le serveur MLflow (tu l‚Äôas d√©j√† fait)\n",
    "Cr√©er l‚Äôexp√©rience MLflow adapt√©e √† ton projet\n",
    "Enregistrer les mod√®les et m√©triques XGBoost et LGBM dans MLflow\n",
    "Tester que tout fonctionne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2c29f2",
   "metadata": {},
   "source": [
    "### D√©marrer MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "746f06d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# starts an MLflow server locally.\n",
    "!mlflow server --host 127.0.0.1 --port 8080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852f4f32",
   "metadata": {},
   "source": [
    "### Configurer MLflow pour notre projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5dbd71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 14:17:58 INFO mlflow.tracking.fluent: Experiment with name 'Forecasting_Energie' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp√©rience MLflow cr√©√©e: Forecasting_Energie (ID: 148799837019663067)\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Connexion au serveur MLflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Cr√©er une exp√©rience MLflow sp√©cifique √† ton projet\n",
    "experiment_name = \"Forecasting_Energie\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "\n",
    "if experiment is None:\n",
    "    experiment_id = client.create_experiment(experiment_name)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "print(f\"Exp√©rience MLflow cr√©√©e: {experiment_name} (ID: {experiment_id})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4e5cb23-bacd-4227-ad3a-1736e71ce9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"C:/Projet_MLOPS/data/df_final_ML2.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51d0fab-21b8-4c7c-9eeb-31e8dea4a117",
   "metadata": {},
   "source": [
    "### Conversions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b508c65f-355a-488d-b84c-200c8b6d590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir la colonne Date en datetime\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "#Convertir la colonne Code INSEE r√©gion en object\n",
    "df['Code INSEE r√©gion'] = df['Code INSEE r√©gion'].astype('object')\n",
    "\n",
    "#Convertir la colonne Loi energie climat 2019 en integer\n",
    "\n",
    "df['Loi energie climat 2019'] = df['Loi energie climat 2019'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b8ac16-9153-4d73-8508-b38dd4e0b80f",
   "metadata": {},
   "source": [
    "### Feature engineering \n",
    "\n",
    "En plus des variables temporelles ajout√©s dans la partie data management (jour, mois, ann√©e, sinus, cosinus, etc), nous allons √©galement proc√©der √† la construction de lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0946f08-4b49-42fd-a0b7-cfafcd98e2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout des lags pour la consommation d'√©nergie jusqu'√† 90 jours\n",
    "for lag in [1, 7, 30, 60, 90, 365]:  # Lags de 1, 7, 30, 60 et 90 jours\n",
    "    df[f'lag_{lag}_Consommation'] = df['Consommation (MWh)'].shift(lag)\n",
    "\n",
    "# Ajout des lags pour les variables climatiques jusqu'√† 90 jours\n",
    "for lag in [1, 7, 30, 60, 90]:\n",
    "    df[f'lag_{lag}_TMin'] = df['TMin (¬∞C)'].shift(lag)\n",
    "    df[f'lag_{lag}_TMax'] = df['TMax (¬∞C)'].shift(lag)\n",
    "    df[f'lag_{lag}_TMoy'] = df['TMoy (¬∞C)'].shift(lag)\n",
    "    df[f'lag_{lag}_Vitesse_vent'] = df['Vitesse du vent √† 100m (m/s)'].shift(lag)\n",
    "    df[f'lag_{lag}_Rayonnement'] = df['Rayonnement solaire global (W/m2)'].shift(lag)\n",
    "\n",
    "# Supprimer les valeurs manquantes cr√©√©es par les lags\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6509ffb1-a014-4a05-b7bc-d2a7ccb96c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_17668\\13998302.py:12: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
      "  df['Consommation_rolling_mean_7'] = df.groupby('Code INSEE r√©gion')['Consommation_rolling_mean_7'].fillna(method='ffill')\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_17668\\13998302.py:12: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['Consommation_rolling_mean_7'] = df.groupby('Code INSEE r√©gion')['Consommation_rolling_mean_7'].fillna(method='ffill')\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_17668\\13998302.py:13: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
      "  df['Consommation_rolling_mean_30'] = df.groupby('Code INSEE r√©gion')['Consommation_rolling_mean_30'].fillna(method='ffill')\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_17668\\13998302.py:13: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['Consommation_rolling_mean_30'] = df.groupby('Code INSEE r√©gion')['Consommation_rolling_mean_30'].fillna(method='ffill')\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_17668\\13998302.py:14: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
      "  df['Consommation_rolling_mean_90'] = df.groupby('Code INSEE r√©gion')['Consommation_rolling_mean_90'].fillna(method='ffill')\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_17668\\13998302.py:14: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['Consommation_rolling_mean_90'] = df.groupby('Code INSEE r√©gion')['Consommation_rolling_mean_90'].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "df = df.sort_values(['Code INSEE r√©gion', 'Date'])\n",
    "\n",
    "# D√©finir les fen√™tres de rolling\n",
    "windows = [7, 30, 90]  # 7 jours, 30 jours, 90 jours\n",
    "\n",
    "for window in windows:\n",
    "    df[f'Consommation_rolling_mean_{window}'] = df.groupby('Code INSEE r√©gion')['Consommation (MWh)'].transform(lambda x: x.rolling(window=window, min_periods=1).mean())\n",
    "\n",
    "#Gestion des NA : \n",
    "\n",
    "# Remplir les NaN avec la m√©thode de forward fill **par r√©gion**\n",
    "df['Consommation_rolling_mean_7'] = df.groupby('Code INSEE r√©gion')['Consommation_rolling_mean_7'].fillna(method='ffill')\n",
    "df['Consommation_rolling_mean_30'] = df.groupby('Code INSEE r√©gion')['Consommation_rolling_mean_30'].fillna(method='ffill')\n",
    "df['Consommation_rolling_mean_90'] = df.groupby('Code INSEE r√©gion')['Consommation_rolling_mean_90'].fillna(method='ffill')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd480930-8c33-459a-b8ad-48cb563a6b69",
   "metadata": {},
   "source": [
    "### Gestion des outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90e9be32-4ab4-4e08-8b03-839e4901909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer Q1, Q3 et l'IQR pour la target\n",
    "Q1 = df['Consommation (MWh)'].quantile(0.25)\n",
    "Q3 = df['Consommation (MWh)'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Identifier les outliers dans la consommation\n",
    "outliers = (df['Consommation (MWh)'] < (Q1 - 1.5 * IQR)) | (df['Consommation (MWh)'] > (Q3 + 1.5 * IQR))\n",
    "\n",
    "# Supprimer les lignes avec outliers dans la target\n",
    "df_cleaned = df[~outliers]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a254bc-5539-4cb4-aef3-81677b44179e",
   "metadata": {},
   "source": [
    "### Train / test split et transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eccc88e4-84a9-42ee-b77c-742d8535ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = df_cleaned.copy() #copier le data set pour ne pas √©craser les modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e37b9936-dd27-4753-8f03-bbd8d8eeaaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# S√©parer la target (y) des features (X)\n",
    "df_transformed = df_transformed.sort_values(by=['Date', 'Code INSEE r√©gion']).\\\n",
    "  reset_index(drop=True)\n",
    "\n",
    "X = df_transformed[['R√©gion','Thermique (MWh)', \n",
    "       'Hydraulique (MWh)', 'Bio√©nergies (MWh)', \n",
    "       'TMoy (¬∞C)', 'Semaine_cos','Semaine_sin', 'lag_7_Consommation', 'lag_30_Consommation', 'lag_365_Consommation', \n",
    "                    'lag_7_TMoy', 'Consommation_rolling_mean_7']]\n",
    "\n",
    "y = df_transformed['Consommation (MWh)']\n",
    "\n",
    "# Split train/test (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)#shuffle = False pour conserver l'ordre chronologique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de4a4e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['R√©gion', 'Thermique (MWh)', 'Hydraulique (MWh)', 'Bio√©nergies (MWh)',\n",
      "       'TMoy (¬∞C)', 'Semaine_cos', 'Semaine_sin', 'lag_7_Consommation',\n",
      "       'lag_30_Consommation', 'lag_365_Consommation', 'lag_7_TMoy',\n",
      "       'Consommation_rolling_mean_7'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72100e47-ea02-46a7-bc9b-1af66fc4524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#Encodage de la variable R√©gion\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# Fit uniquement sur X_train et transformer X_train\n",
    "X_train_encoded = encoder.fit_transform(X_train[['R√©gion']])\n",
    "X_train_encoded_df = pd.DataFrame(X_train_encoded, columns=encoder.get_feature_names_out(['R√©gion']), index=X_train.index)\n",
    "\n",
    "# Transformer X_test (sans refit)\n",
    "X_test_encoded = encoder.transform(X_test[['R√©gion']])\n",
    "X_test_encoded_df = pd.DataFrame(X_test_encoded, columns=encoder.get_feature_names_out(['R√©gion']), index=X_test.index)\n",
    "\n",
    "# Concat√©ner les colonnes encod√©es avec les autres features\n",
    "X_train = pd.concat([X_train.drop(columns=['R√©gion']), X_train_encoded_df], axis=1)\n",
    "X_test = pd.concat([X_test.drop(columns=['R√©gion']), X_test_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8288e5b-ebac-474a-975c-f9da2553f68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R√©gion_Auvergne-Rh√¥ne-Alpes          0.452152\n",
      "R√©gion_√éle-de-France                 0.438790\n",
      "R√©gion_Centre-Val de Loire           0.353461\n",
      "R√©gion_Bourgogne-Franche-Comt√©       0.305078\n",
      "R√©gion_Bretagne                      0.284825\n",
      "R√©gion_Hauts-de-France               0.215121\n",
      "R√©gion_Pays de la Loire              0.198573\n",
      "R√©gion_Normandie                     0.188714\n",
      "R√©gion_Grand Est                     0.132741\n",
      "R√©gion_Nouvelle-Aquitaine            0.098058\n",
      "R√©gion_Provence-Alpes-C√¥te d'Azur    0.045452\n",
      "R√©gion_Occitanie                     0.004412\n",
      "Name: Consommation (MWh), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Concat√©ner X_train et y_train pour faciliter l'analyse\n",
    "df_train = X_train[['R√©gion_Auvergne-Rh√¥ne-Alpes',\n",
    "       'R√©gion_Bourgogne-Franche-Comt√©', 'R√©gion_Bretagne',\n",
    "       'R√©gion_Centre-Val de Loire', 'R√©gion_Grand Est',\n",
    "       'R√©gion_Hauts-de-France', 'R√©gion_Normandie',\n",
    "       'R√©gion_Nouvelle-Aquitaine', 'R√©gion_Occitanie',\n",
    "       'R√©gion_Pays de la Loire', \"R√©gion_Provence-Alpes-C√¥te d'Azur\",\n",
    "       'R√©gion_√éle-de-France']].copy()\n",
    "df_train['Consommation (MWh)'] = y_train  \n",
    "\n",
    "# Calculer la corr√©lation de chaque feature avec la target\n",
    "correlations = df_train.corr()['Consommation (MWh)'].drop('Consommation (MWh)')  \n",
    "\n",
    "# Trier par ordre d√©croissant d'importance absolue\n",
    "correlations = correlations.abs().sort_values(ascending=False)\n",
    "\n",
    "# Afficher les variables les plus corr√©l√©es\n",
    "print(correlations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2be1779e-4fc6-4689-b6d8-b0985f429209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Garder uniquement les r√©gions avec une corr√©lation sup√©rieur √† 0.30\n",
    "X_train = X_train.drop(columns=['R√©gion_Bretagne',\n",
    "        'R√©gion_Grand Est','R√©gion_Hauts-de-France', 'R√©gion_Normandie',\n",
    "       'R√©gion_Nouvelle-Aquitaine', 'R√©gion_Occitanie',\n",
    "       'R√©gion_Pays de la Loire', \"R√©gion_Provence-Alpes-C√¥te d'Azur\"\n",
    "       ])\n",
    "\n",
    "X_test = X_test.drop(columns=['R√©gion_Bretagne',\n",
    "        'R√©gion_Grand Est','R√©gion_Hauts-de-France', 'R√©gion_Normandie',\n",
    "       'R√©gion_Nouvelle-Aquitaine', 'R√©gion_Occitanie',\n",
    "       'R√©gion_Pays de la Loire', \"R√©gion_Provence-Alpes-C√¥te d'Azur\"\n",
    "       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d06abb62-0bad-4eae-8878-714fd105db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Colonnes num√©riques √† standardiser\n",
    "normalize_cols = ['Thermique (MWh)', \n",
    "       'Hydraulique (MWh)', 'Bio√©nergies (MWh)', \n",
    "       'TMoy (¬∞C)',  'lag_7_Consommation', 'lag_30_Consommation', 'lag_365_Consommation', \n",
    "                    'lag_7_TMoy', 'Consommation_rolling_mean_7']\n",
    "\n",
    "# Initialisation des scalers\n",
    "scaler_X = StandardScaler()\n",
    "\n",
    "# Standardiser X_train \n",
    "X_train[normalize_cols] = scaler_X.fit_transform(X_train[normalize_cols])\n",
    "\n",
    "# Appliquer la transformation sur  X_test (sans refit)\n",
    "X_test[normalize_cols] = scaler_X.transform(X_test[normalize_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecbb7ce-9723-4216-aecf-528fa2eab847",
   "metadata": {},
   "source": [
    "### Entra√Ænement du premier mod√®le ML XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd50d44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Meilleurs param√®tres : {'colsample_bytree': 1.0, 'gamma': 0, 'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/21 14:28:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train : 2760.1172631694803\n",
      "MSE train: 15033056.535677444\n",
      "R¬≤ train : 0.9928962319347773\n",
      "MAPE train : 3.0290847926004174%\n",
      "MAE test : 4797.507268818902\n",
      "MSE test : 44922613.22361186\n",
      "R¬≤ test : 0.9760808807769817\n",
      "MAPE test : 5.899805841171993%\n",
      "üèÉ View run serious-kite-968 at: http://127.0.0.1:8080/#/experiments/148799837019663067/runs/db9233bb4f784514bb004d26f5bd8077\n",
      "üß™ View experiment at: http://127.0.0.1:8080/#/experiments/148799837019663067\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# D√©finir le mod√®le XGBoost\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# D√©finir les hyperparam√®tres √† tester avec GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [400, 500],  # Nombre d'estimateurs\n",
    "    'learning_rate': [0.01, 0.05, 0.1],  # Taux d'apprentissage\n",
    "    'max_depth': [5, 6, 7],  # Profondeur des arbres\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0],  # Proportion de features pour chaque arbre\n",
    "    'gamma': [0, 0.3],  # Lutte contre l‚Äôoverfitting en contr√¥lant les branches des arbres\n",
    "}\n",
    "\n",
    "# GridSearchCV : recherche exhaustive des meilleurs param√®tres\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, \n",
    "                           cv=3, scoring='neg_mean_absolute_error', \n",
    "                           n_jobs=-1, verbose=1)\n",
    "\n",
    "# D√©marrer un suivi d'exp√©rience avec MLflow\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Entra√Æner le mod√®le avec la recherche sur la grille\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Afficher les meilleurs param√®tres trouv√©s\n",
    "    print(f\"Meilleurs param√®tres : {grid_search.best_params_}\")\n",
    "    \n",
    "    # Log des meilleurs param√®tres\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "\n",
    "    # Utiliser le mod√®le optimal pour faire des pr√©dictions\n",
    "    best_model_xgb = grid_search.best_estimator_\n",
    "\n",
    "    # Validation crois√©e avec TimeSeriesSplit\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    \n",
    "    mae_scores, mse_scores, mape_scores, r2_scores = [], [], [], []\n",
    "\n",
    "    for train_index, test_index in tscv.split(X_train):\n",
    "        X_train_iter, X_test_iter = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_iter, y_test_iter = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Entra√Ænement avec le meilleur mod√®le trouv√© par GridSearchCV\n",
    "        best_model_xgb.fit(X_train_iter, y_train_iter)\n",
    "\n",
    "        # Pr√©dictions\n",
    "        y_pred = best_model_xgb.predict(X_test_iter)\n",
    "\n",
    "        # Calcul des m√©triques\n",
    "        mae = mean_absolute_error(y_test_iter, y_pred)\n",
    "        mse = mean_squared_error(y_test_iter, y_pred)\n",
    "        mape = np.mean(np.abs((y_test_iter - y_pred) / y_test_iter)) * 100\n",
    "        r2 = r2_score(y_test_iter, y_pred)\n",
    "\n",
    "        mae_scores.append(mae)\n",
    "        mse_scores.append(mse)\n",
    "        mape_scores.append(mape)\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "    # Log des r√©sultats de validation crois√©e dans MLflow\n",
    "    mlflow.log_metric(\"MAE moyen\", np.mean(mae_scores))\n",
    "    mlflow.log_metric(\"MAPE moyen\", np.mean(mape_scores))\n",
    "    mlflow.log_metric(\"MSE moyen\", np.mean(mse_scores))\n",
    "    mlflow.log_metric(\"R¬≤ moyen\", np.mean(r2_scores))\n",
    "\n",
    "    # Pr√©dictions sur l'ensemble de test et de train\n",
    "    y_pred_train = best_model_xgb.predict(X_train)\n",
    "    y_pred_test = best_model_xgb.predict(X_test)\n",
    "\n",
    "    # Calcul des m√©triques sur l'ensemble de train\n",
    "    mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    mape_train = np.mean(np.abs((y_train - y_pred_train) / y_train)) * 100  # MAPE en %\n",
    "\n",
    "    # Calcul des m√©triques sur l'ensemble de test\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    mape_test = np.mean(np.abs((y_test - y_pred_test) / y_test)) * 100  # MAPE en %\n",
    "\n",
    "    # Log des r√©sultats de test et train dans MLflow\n",
    "    mlflow.log_metric(\"MAE train\", mae_train)\n",
    "    mlflow.log_metric(\"MSE train\", mse_train)\n",
    "    mlflow.log_metric(\"R¬≤ train\", r2_train)\n",
    "    mlflow.log_metric(\"MAPE train\", mape_train)\n",
    "\n",
    "    mlflow.log_metric(\"MAE test\", mae_test)\n",
    "    mlflow.log_metric(\"MSE test\", mse_test)\n",
    "    mlflow.log_metric(\"R¬≤ test\", r2_test)\n",
    "    mlflow.log_metric(\"MAPE test\", mape_test)\n",
    "\n",
    "    # Sauvegarder le mod√®le 'best_model_xgb' dans un fichier\n",
    "    joblib.dump(best_model_xgb, 'best_model_xgb.pkl')\n",
    "\n",
    "    # Log du mod√®le XGBoost dans MLflow\n",
    "    mlflow.sklearn.log_model(best_model_xgb, \"best_model\")\n",
    "\n",
    "    # Charger le mod√®le sauvegard√©\n",
    "    best_model_xgb_final = joblib.load('best_model_xgb.pkl')\n",
    "\n",
    "    print(f\"MAE train : {mae_train}\")\n",
    "    print(f\"MSE train: {mse_train}\")\n",
    "    print(f\"R¬≤ train : {r2_train}\")\n",
    "    print(f\"MAPE train : {mape_train}%\")\n",
    "\n",
    "    print(f\"MAE test : {mae_test}\")\n",
    "    print(f\"MSE test : {mse_test}\")\n",
    "    print(f\"R¬≤ test : {r2_test}\")\n",
    "    print(f\"MAPE test : {mape_test}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8bdaeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
