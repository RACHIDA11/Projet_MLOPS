{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b01d4-39ce-405e-9160-32beb4472d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "#from sklearn.compose import ColumnTransformer\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#import xgboost as xgb\n",
    "#from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "#import scipy.stats as stats\n",
    "#from statsmodels.graphics.tsaplots import plot_acf\n",
    "#from scipy.stats import skew, kurtosis, probplot\n",
    "#from statsmodels.stats.stattools import jarque_bera\n",
    "#from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "#from scipy.stats import shapiro\n",
    "#from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "#from lightgbm import LGBMRegressor\n",
    "#import lightgbm as lgb\n",
    "#from lightgbm import early_stopping\n",
    "#from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, mean_absolute_error, r2_score, make_scorer\n",
    "#from sklearn.model_selection import cross_validate\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#import plotly.graph_objects as go\n",
    "#import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34e335c-12b0-4564-9bb7-bc4799510411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import warnings\n",
    "#warnings.simplefilter(action='ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91dec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlflow\n",
    "#!pip install --upgrade jinja2\n",
    "#!pip install --upgrade Flask\n",
    "#!pip install setuptools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d65537",
   "metadata": {},
   "source": [
    "### Plan d’Action\n",
    "Démarrer le serveur MLflow (tu l’as déjà fait)\n",
    "Créer l’expérience MLflow adaptée à ton projet\n",
    "Enregistrer les modèles et métriques XGBoost et LGBM dans MLflow\n",
    "Tester que tout fonctionne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2c29f2",
   "metadata": {},
   "source": [
    "### Démarrer MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "746f06d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# starts an MLflow server locally.\n",
    "!mlflow server --host 127.0.0.1 --port 8080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852f4f32",
   "metadata": {},
   "source": [
    "### Configurer MLflow pour notre projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5dbd71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/20 22:46:41 INFO mlflow.tracking.fluent: Experiment with name 'Forecasting_Energie' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expérience MLflow créée: Forecasting_Energie (ID: 494854308983366684)\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Connexion au serveur MLflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Créer une expérience MLflow spécifique à ton projet\n",
    "experiment_name = \"Forecasting_Energie\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "\n",
    "if experiment is None:\n",
    "    experiment_id = client.create_experiment(experiment_name)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "print(f\"Expérience MLflow créée: {experiment_name} (ID: {experiment_id})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4e5cb23-bacd-4227-ad3a-1736e71ce9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Projet_MLOPS/data/df_final_ML2.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51d0fab-21b8-4c7c-9eeb-31e8dea4a117",
   "metadata": {},
   "source": [
    "### Conversions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b508c65f-355a-488d-b84c-200c8b6d590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir la colonne Date en datetime\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "#Convertir la colonne Code INSEE région en object\n",
    "df['Code INSEE région'] = df['Code INSEE région'].astype('object')\n",
    "\n",
    "#Convertir la colonne Loi energie climat 2019 en integer\n",
    "\n",
    "df['Loi energie climat 2019'] = df['Loi energie climat 2019'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b8ac16-9153-4d73-8508-b38dd4e0b80f",
   "metadata": {},
   "source": [
    "### Feature engineering \n",
    "\n",
    "En plus des variables temporelles ajoutés dans la partie data management (jour, mois, année, sinus, cosinus, etc), nous allons également procéder à la construction de lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0946f08-4b49-42fd-a0b7-cfafcd98e2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout des lags pour la consommation d'énergie jusqu'à 90 jours\n",
    "for lag in [1, 7, 30, 60, 90, 365]:  # Lags de 1, 7, 30, 60 et 90 jours\n",
    "    df[f'lag_{lag}_Consommation'] = df['Consommation (MWh)'].shift(lag)\n",
    "\n",
    "# Ajout des lags pour les variables climatiques jusqu'à 90 jours\n",
    "for lag in [1, 7, 30, 60, 90]:\n",
    "    df[f'lag_{lag}_TMin'] = df['TMin (°C)'].shift(lag)\n",
    "    df[f'lag_{lag}_TMax'] = df['TMax (°C)'].shift(lag)\n",
    "    df[f'lag_{lag}_TMoy'] = df['TMoy (°C)'].shift(lag)\n",
    "    df[f'lag_{lag}_Vitesse_vent'] = df['Vitesse du vent à 100m (m/s)'].shift(lag)\n",
    "    df[f'lag_{lag}_Rayonnement'] = df['Rayonnement solaire global (W/m2)'].shift(lag)\n",
    "\n",
    "# Supprimer les valeurs manquantes créées par les lags\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6509ffb1-a014-4a05-b7bc-d2a7ccb96c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_29604\\13998302.py:12: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
      "  df['Consommation_rolling_mean_7'] = df.groupby('Code INSEE région')['Consommation_rolling_mean_7'].fillna(method='ffill')\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_29604\\13998302.py:12: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['Consommation_rolling_mean_7'] = df.groupby('Code INSEE région')['Consommation_rolling_mean_7'].fillna(method='ffill')\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_29604\\13998302.py:13: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
      "  df['Consommation_rolling_mean_30'] = df.groupby('Code INSEE région')['Consommation_rolling_mean_30'].fillna(method='ffill')\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_29604\\13998302.py:13: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['Consommation_rolling_mean_30'] = df.groupby('Code INSEE région')['Consommation_rolling_mean_30'].fillna(method='ffill')\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_29604\\13998302.py:14: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
      "  df['Consommation_rolling_mean_90'] = df.groupby('Code INSEE région')['Consommation_rolling_mean_90'].fillna(method='ffill')\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_29604\\13998302.py:14: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['Consommation_rolling_mean_90'] = df.groupby('Code INSEE région')['Consommation_rolling_mean_90'].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "df = df.sort_values(['Code INSEE région', 'Date'])\n",
    "\n",
    "# Définir les fenêtres de rolling\n",
    "windows = [7, 30, 90]  # 7 jours, 30 jours, 90 jours\n",
    "\n",
    "for window in windows:\n",
    "    df[f'Consommation_rolling_mean_{window}'] = df.groupby('Code INSEE région')['Consommation (MWh)'].transform(lambda x: x.rolling(window=window, min_periods=1).mean())\n",
    "\n",
    "#Gestion des NA : \n",
    "\n",
    "# Remplir les NaN avec la méthode de forward fill **par région**\n",
    "df['Consommation_rolling_mean_7'] = df.groupby('Code INSEE région')['Consommation_rolling_mean_7'].fillna(method='ffill')\n",
    "df['Consommation_rolling_mean_30'] = df.groupby('Code INSEE région')['Consommation_rolling_mean_30'].fillna(method='ffill')\n",
    "df['Consommation_rolling_mean_90'] = df.groupby('Code INSEE région')['Consommation_rolling_mean_90'].fillna(method='ffill')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd480930-8c33-459a-b8ad-48cb563a6b69",
   "metadata": {},
   "source": [
    "### Gestion des outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90e9be32-4ab4-4e08-8b03-839e4901909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer Q1, Q3 et l'IQR pour la target\n",
    "Q1 = df['Consommation (MWh)'].quantile(0.25)\n",
    "Q3 = df['Consommation (MWh)'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Identifier les outliers dans la consommation\n",
    "outliers = (df['Consommation (MWh)'] < (Q1 - 1.5 * IQR)) | (df['Consommation (MWh)'] > (Q3 + 1.5 * IQR))\n",
    "\n",
    "# Supprimer les lignes avec outliers dans la target\n",
    "df_cleaned = df[~outliers]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a254bc-5539-4cb4-aef3-81677b44179e",
   "metadata": {},
   "source": [
    "### Train / test split et transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eccc88e4-84a9-42ee-b77c-742d8535ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = df_cleaned.copy() #copier le data set pour ne pas écraser les modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e37b9936-dd27-4753-8f03-bbd8d8eeaaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Séparer la target (y) des features (X)\n",
    "df_transformed = df_transformed.sort_values(by=['Date', 'Code INSEE région']).\\\n",
    "  reset_index(drop=True)\n",
    "\n",
    "X = df_transformed[['Région','Thermique (MWh)', \n",
    "       'Hydraulique (MWh)', 'Bioénergies (MWh)', \n",
    "       'TMoy (°C)', 'Semaine_cos','Semaine_sin', 'lag_7_Consommation', 'lag_30_Consommation', 'lag_365_Consommation', \n",
    "                    'lag_7_TMoy', 'Consommation_rolling_mean_7']]\n",
    "\n",
    "y = df_transformed['Consommation (MWh)']\n",
    "\n",
    "# Split train/test (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)#shuffle = False pour conserver l'ordre chronologique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72100e47-ea02-46a7-bc9b-1af66fc4524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#Encodage de la variable Région\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# Fit uniquement sur X_train et transformer X_train\n",
    "X_train_encoded = encoder.fit_transform(X_train[['Région']])\n",
    "X_train_encoded_df = pd.DataFrame(X_train_encoded, columns=encoder.get_feature_names_out(['Région']), index=X_train.index)\n",
    "\n",
    "# Transformer X_test (sans refit)\n",
    "X_test_encoded = encoder.transform(X_test[['Région']])\n",
    "X_test_encoded_df = pd.DataFrame(X_test_encoded, columns=encoder.get_feature_names_out(['Région']), index=X_test.index)\n",
    "\n",
    "# Concaténer les colonnes encodées avec les autres features\n",
    "X_train = pd.concat([X_train.drop(columns=['Région']), X_train_encoded_df], axis=1)\n",
    "X_test = pd.concat([X_test.drop(columns=['Région']), X_test_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8288e5b-ebac-474a-975c-f9da2553f68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Région_Auvergne-Rhône-Alpes          0.452152\n",
      "Région_Île-de-France                 0.438790\n",
      "Région_Centre-Val de Loire           0.353461\n",
      "Région_Bourgogne-Franche-Comté       0.305078\n",
      "Région_Bretagne                      0.284825\n",
      "Région_Hauts-de-France               0.215121\n",
      "Région_Pays de la Loire              0.198573\n",
      "Région_Normandie                     0.188714\n",
      "Région_Grand Est                     0.132741\n",
      "Région_Nouvelle-Aquitaine            0.098058\n",
      "Région_Provence-Alpes-Côte d'Azur    0.045452\n",
      "Région_Occitanie                     0.004412\n",
      "Name: Consommation (MWh), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Concaténer X_train et y_train pour faciliter l'analyse\n",
    "df_train = X_train[['Région_Auvergne-Rhône-Alpes',\n",
    "       'Région_Bourgogne-Franche-Comté', 'Région_Bretagne',\n",
    "       'Région_Centre-Val de Loire', 'Région_Grand Est',\n",
    "       'Région_Hauts-de-France', 'Région_Normandie',\n",
    "       'Région_Nouvelle-Aquitaine', 'Région_Occitanie',\n",
    "       'Région_Pays de la Loire', \"Région_Provence-Alpes-Côte d'Azur\",\n",
    "       'Région_Île-de-France']].copy()\n",
    "df_train['Consommation (MWh)'] = y_train  \n",
    "\n",
    "# Calculer la corrélation de chaque feature avec la target\n",
    "correlations = df_train.corr()['Consommation (MWh)'].drop('Consommation (MWh)')  \n",
    "\n",
    "# Trier par ordre décroissant d'importance absolue\n",
    "correlations = correlations.abs().sort_values(ascending=False)\n",
    "\n",
    "# Afficher les variables les plus corrélées\n",
    "print(correlations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2be1779e-4fc6-4689-b6d8-b0985f429209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Garder uniquement les régions avec une corrélation supérieur à 0.30\n",
    "X_train = X_train.drop(columns=['Région_Bretagne',\n",
    "        'Région_Grand Est','Région_Hauts-de-France', 'Région_Normandie',\n",
    "       'Région_Nouvelle-Aquitaine', 'Région_Occitanie',\n",
    "       'Région_Pays de la Loire', \"Région_Provence-Alpes-Côte d'Azur\"\n",
    "       ])\n",
    "\n",
    "X_test = X_test.drop(columns=['Région_Bretagne',\n",
    "        'Région_Grand Est','Région_Hauts-de-France', 'Région_Normandie',\n",
    "       'Région_Nouvelle-Aquitaine', 'Région_Occitanie',\n",
    "       'Région_Pays de la Loire', \"Région_Provence-Alpes-Côte d'Azur\"\n",
    "       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d06abb62-0bad-4eae-8878-714fd105db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Colonnes numériques à standardiser\n",
    "normalize_cols = ['Thermique (MWh)', \n",
    "       'Hydraulique (MWh)', 'Bioénergies (MWh)', \n",
    "       'TMoy (°C)',  'lag_7_Consommation', 'lag_30_Consommation', 'lag_365_Consommation', \n",
    "                    'lag_7_TMoy', 'Consommation_rolling_mean_7']\n",
    "\n",
    "# Initialisation des scalers\n",
    "scaler_X = StandardScaler()\n",
    "\n",
    "# Standardiser X_train \n",
    "X_train[normalize_cols] = scaler_X.fit_transform(X_train[normalize_cols])\n",
    "\n",
    "# Appliquer la transformation sur  X_test (sans refit)\n",
    "X_test[normalize_cols] = scaler_X.transform(X_test[normalize_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3651f260-346b-4282-9321-f7fac1b22f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(\"X_train_vf2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecbb7ce-9723-4216-aecf-528fa2eab847",
   "metadata": {},
   "source": [
    "### Entraînement du premier modèle ML XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b3d430-f439-437e-af69-17ee4c654f20",
   "metadata": {},
   "source": [
    "Utilisation de grid search pour nous aider dans le choix des hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd50d44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "🏃 View run kindly-owl-479 at: http://127.0.0.1:8080/#/experiments/494854308983366684/runs/f184e90ca79642ddadbe5aec5864c868\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/494854308983366684\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Démarrer un suivi d'expérience avec MLflow\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m mlflow.start_run():\n\u001b[32m     28\u001b[39m \n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# Entraîner le modèle avec la recherche sur la grille\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     \u001b[38;5;66;03m# Afficher les meilleurs paramètres trouvés\u001b[39;00m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMeilleurs paramètres : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search.best_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projet_MLOPS\\venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projet_MLOPS\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projet_MLOPS\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1569\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1570\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1571\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projet_MLOPS\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projet_MLOPS\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projet_MLOPS\\venv\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projet_MLOPS\\venv\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projet_MLOPS\\venv\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# Définir le modèle XGBoost\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Définir les hyperparamètres à tester avec GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [400, 500],  # Nombre d'estimateurs\n",
    "    'learning_rate': [0.01, 0.05, 0.1],  # Taux d'apprentissage\n",
    "    'max_depth': [5, 6, 7],  # Profondeur des arbres\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0],  # Proportion de features pour chaque arbre\n",
    "    'gamma': [0, 0.3],  # Lutte contre l’overfitting en contrôlant les branches des arbres\n",
    "}\n",
    "\n",
    "# GridSearchCV : recherche exhaustive des meilleurs paramètres\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, \n",
    "                           cv=3, scoring='neg_mean_absolute_error', \n",
    "                           n_jobs=-1, verbose=1)\n",
    "\n",
    "# Démarrer un suivi d'expérience avec MLflow\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Entraîner le modèle avec la recherche sur la grille\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Afficher les meilleurs paramètres trouvés\n",
    "    print(f\"Meilleurs paramètres : {grid_search.best_params_}\")\n",
    "    \n",
    "    # Log des meilleurs paramètres\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "\n",
    "    # Utiliser le modèle optimal pour faire des prédictions\n",
    "    best_model_xgb = grid_search.best_estimator_\n",
    "\n",
    "    # Validation croisée avec TimeSeriesSplit\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    \n",
    "    mae_scores, mse_scores, mape_scores, r2_scores = [], [], [], []\n",
    "\n",
    "    for train_index, test_index in tscv.split(X_train):\n",
    "        X_train_iter, X_test_iter = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_iter, y_test_iter = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Entraînement avec le meilleur modèle trouvé par GridSearchCV\n",
    "        best_model_xgb.fit(X_train_iter, y_train_iter)\n",
    "\n",
    "        # Prédictions\n",
    "        y_pred = best_model_xgb.predict(X_test_iter)\n",
    "\n",
    "        # Calcul des métriques\n",
    "        mae = mean_absolute_error(y_test_iter, y_pred)\n",
    "        mse = mean_squared_error(y_test_iter, y_pred)\n",
    "        mape = np.mean(np.abs((y_test_iter - y_pred) / y_test_iter)) * 100\n",
    "        r2 = r2_score(y_test_iter, y_pred)\n",
    "\n",
    "        mae_scores.append(mae)\n",
    "        mse_scores.append(mse)\n",
    "        mape_scores.append(mape)\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "    # Log des résultats de validation croisée dans MLflow\n",
    "    mlflow.log_metric(\"MAE moyen\", np.mean(mae_scores))\n",
    "    mlflow.log_metric(\"MAPE moyen\", np.mean(mape_scores))\n",
    "    mlflow.log_metric(\"MSE moyen\", np.mean(mse_scores))\n",
    "    mlflow.log_metric(\"R² moyen\", np.mean(r2_scores))\n",
    "\n",
    "    # Prédictions sur l'ensemble de test et de train\n",
    "    y_pred_train = best_model_xgb.predict(X_train)\n",
    "    y_pred_test = best_model_xgb.predict(X_test)\n",
    "\n",
    "    # Calcul des métriques sur l'ensemble de train\n",
    "    mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    mape_train = np.mean(np.abs((y_train - y_pred_train) / y_train)) * 100  # MAPE en %\n",
    "\n",
    "    # Calcul des métriques sur l'ensemble de test\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    mape_test = np.mean(np.abs((y_test - y_pred_test) / y_test)) * 100  # MAPE en %\n",
    "\n",
    "    # Log des résultats de test et train dans MLflow\n",
    "    mlflow.log_metric(\"MAE train\", mae_train)\n",
    "    mlflow.log_metric(\"MSE train\", mse_train)\n",
    "    mlflow.log_metric(\"R² train\", r2_train)\n",
    "    mlflow.log_metric(\"MAPE train\", mape_train)\n",
    "\n",
    "    mlflow.log_metric(\"MAE test\", mae_test)\n",
    "    mlflow.log_metric(\"MSE test\", mse_test)\n",
    "    mlflow.log_metric(\"R² test\", r2_test)\n",
    "    mlflow.log_metric(\"MAPE test\", mape_test)\n",
    "\n",
    "    # Sauvegarder le modèle 'best_model_xgb' dans un fichier\n",
    "    joblib.dump(best_model_xgb, 'best_model_xgb.pkl')\n",
    "\n",
    "    # Log du modèle XGBoost dans MLflow\n",
    "    mlflow.sklearn.log_model(best_model_xgb, \"best_model\")\n",
    "\n",
    "    # Charger le modèle sauvegardé\n",
    "    best_model_xgb_final = joblib.load('best_model_xgb.pkl')\n",
    "\n",
    "    print(f\"MAE train : {mae_train}\")\n",
    "    print(f\"MSE train: {mse_train}\")\n",
    "    print(f\"R² train : {r2_train}\")\n",
    "    print(f\"MAPE train : {mape_train}%\")\n",
    "\n",
    "    print(f\"MAE test : {mae_test}\")\n",
    "    print(f\"MSE test : {mse_test}\")\n",
    "    print(f\"R² test : {r2_test}\")\n",
    "    print(f\"MAPE test : {mape_test}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e012a98-d8fe-4bfd-977a-1ec45d6eab0c",
   "metadata": {},
   "source": [
    "### Modèle LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5fb7e9-1851-4dec-9626-e85af4c95f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le modèle 'best_model_lgb' dans un fichier\n",
    "joblib.dump(best_model_lgb, 'best_model_lgbm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e215a1-dd99-4383-8cd7-15fa1a3f3f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle sauvegardé\n",
    "best_model_loaded= joblib.load('best_model_lgbm.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17e9939",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5128704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew, kurtosis, jarque_bera, shapiro\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "# Initialiser MLflow\n",
    "mlflow.set_experiment(\"LightGBM_Experiment\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Définition du modèle LightGBM\n",
    "    model_lgb = lgb.LGBMRegressor(random_state=42)\n",
    "\n",
    "    # Hyperparamètres à tester avec GridSearchCV\n",
    "    param_grid_lgb = {\n",
    "        'n_estimators': [200, 500],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'num_leaves': [31, 40, 50],\n",
    "        'colsample_bytree': [0.7, 0.8, 1.0],\n",
    "        'subsample': [0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    # GridSearchCV pour la recherche des meilleurs hyperparamètres\n",
    "    grid_search_lgb = GridSearchCV(estimator=model_lgb, param_grid=param_grid_lgb, \n",
    "                                   cv=3, scoring='neg_mean_absolute_error', \n",
    "                                   n_jobs=-1, verbose=1)\n",
    "\n",
    "    # Entraîner le modèle avec GridSearch\n",
    "    grid_search_lgb.fit(X_train, y_train)\n",
    "\n",
    "    # Récupérer le meilleur modèle et hyperparamètres\n",
    "    best_model_lgb = grid_search_lgb.best_estimator_\n",
    "    best_params = grid_search_lgb.best_params_\n",
    "\n",
    "    # Log des hyperparamètres trouvés par GridSearch\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # Validation croisée avec TimeSeriesSplit\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    mae_scores, mse_scores, mape_scores, r2_scores = [], [], [], []\n",
    "\n",
    "    for train_index, test_index in tscv.split(X_train):\n",
    "        X_train_iter, X_test_iter = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_iter, y_test_iter = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Entraîner le meilleur modèle\n",
    "        best_model_lgb.fit(X_train_iter, y_train_iter)\n",
    "\n",
    "        # Prédictions\n",
    "        y_pred = best_model_lgb.predict(X_test_iter)\n",
    "\n",
    "        # Calcul des métriques\n",
    "        mae = mean_absolute_error(y_test_iter, y_pred)\n",
    "        mse = mean_squared_error(y_test_iter, y_pred)\n",
    "        mape = np.mean(np.abs((y_test_iter - y_pred) / y_test_iter)) * 100\n",
    "        r2 = r2_score(y_test_iter, y_pred)\n",
    "\n",
    "        mae_scores.append(mae)\n",
    "        mse_scores.append(mse)\n",
    "        mape_scores.append(mape)\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "    # Moyennes des métriques\n",
    "    avg_mae, avg_mse, avg_mape, avg_r2 = np.mean(mae_scores), np.mean(mse_scores), np.mean(mape_scores), np.mean(r2_scores)\n",
    "\n",
    "    # Log des métriques dans MLflow\n",
    "    mlflow.log_metric(\"MAE_CV\", avg_mae)\n",
    "    mlflow.log_metric(\"MSE_CV\", avg_mse)\n",
    "    mlflow.log_metric(\"MAPE_CV\", avg_mape)\n",
    "    mlflow.log_metric(\"R2_CV\", avg_r2)\n",
    "\n",
    "    # Sauvegarde du meilleur modèle\n",
    "    joblib.dump(best_model_lgb, 'best_model_lgbm.pkl')\n",
    "    mlflow.sklearn.log_model(best_model_lgb, \"model\")\n",
    "\n",
    "    # Prédictions sur l'ensemble train et test\n",
    "    y_pred_train = best_model_lgb.predict(X_train)\n",
    "    y_pred_test = best_model_lgb.predict(X_test)\n",
    "\n",
    "    # Calcul des métriques finales\n",
    "    mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    mape_train = np.mean(np.abs((y_train - y_pred_train) / y_train)) * 100\n",
    "\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    mape_test = np.mean(np.abs((y_test - y_pred_test) / y_test)) * 100\n",
    "\n",
    "    # Log des métriques finales\n",
    "    mlflow.log_metric(\"MAE_Train\", mae_train)\n",
    "    mlflow.log_metric(\"MSE_Train\", mse_train)\n",
    "    mlflow.log_metric(\"MAPE_Train\", mape_train)\n",
    "    mlflow.log_metric(\"R2_Train\", r2_train)\n",
    "\n",
    "    mlflow.log_metric(\"MAE_Test\", mae_test)\n",
    "    mlflow.log_metric(\"MSE_Test\", mse_test)\n",
    "    mlflow.log_metric(\"MAPE_Test\", mape_test)\n",
    "    mlflow.log_metric(\"R2_Test\", r2_test)\n",
    "\n",
    "    print(f\"MAE Train: {mae_train}, MAE Test: {mae_test}\")\n",
    "    print(f\"MSE Train: {mse_train}, MSE Test: {mse_test}\")\n",
    "    print(f\"R² Train: {r2_train}, R² Test: {r2_test}\")\n",
    "    print(f\"MAPE Train: {mape_train}%, MAPE Test: {mape_test}%\")\n",
    "\n",
    "    # Analyse des résidus\n",
    "    residuals = y_test - y_pred_test\n",
    "\n",
    "    plt.hist(residuals, bins=50, alpha=0.75)\n",
    "    plt.title(\"Distribution des résidus\")\n",
    "    plt.xlabel(\"Résidus\")\n",
    "    plt.ylabel(\"Fréquence\")\n",
    "    plt.savefig(\"residuals_distribution.png\")\n",
    "    mlflow.log_artifact(\"residuals_distribution.png\")\n",
    "\n",
    "    # Autres statistiques sur les résidus\n",
    "    skewness_residus = skew(residuals)\n",
    "    kurtosis_residus = kurtosis(residuals)\n",
    "\n",
    "    mlflow.log_metric(\"Skewness_Residus\", skewness_residus)\n",
    "    mlflow.log_metric(\"Kurtosis_Residus\", kurtosis_residus)\n",
    "\n",
    "    print(f\"Skewness des résidus : {skewness_residus}\")\n",
    "    print(f\"Kurtosis des résidus : {kurtosis_residus}\")\n",
    "\n",
    "    # Test de normalité des résidus\n",
    "    jb_test = jarque_bera(residuals)\n",
    "    sw_test = shapiro(residuals)\n",
    "    \n",
    "    mlflow.log_metric(\"Jarque-Bera\", jb_test[0])\n",
    "    mlflow.log_metric(\"Shapiro-Wilk\", sw_test[0])\n",
    "\n",
    "    print(\"Test Jarque-Bera:\", jb_test)\n",
    "    print(\"Test Shapiro-Wilk:\", sw_test)\n",
    "\n",
    "    # Fin de l'expérience MLflow\n",
    "    mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8bdaeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
